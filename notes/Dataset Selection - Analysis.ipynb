{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Selection / Analysis\n",
    "\n",
    "For our model, we are going to be creating a model that can be feed an image (size 28x28) and determine the character that is found on that image.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "There were a few different datasets that were available:\n",
    "\n",
    "* [MNIST Handwritten Digits](http://yann.lecun.com/exdb/mnist/)\n",
    "* [ICDAR 2003 Competition Set](http://www.iapr-tc11.org/mediawiki/index.php/ICDAR_2003_Robust_Reading_Competitions#Robust_Reading_and_Text_Locating)\n",
    "\n",
    "We have decided at this time to use the `ICDAR` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.iapr-tc11.org/dataset/ICDAR2003_RobustReading/TrialTrain/char.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Munging\n",
    "\n",
    "The first thing we are going to do is to update the catalog from xml to json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree\n",
    "import json\n",
    "\n",
    "data_path = '../raw_data'\n",
    "char_xml = xml.etree.ElementTree.parse(os.path.join(data_path, 'char.xml')).getroot()\n",
    "\n",
    "output_object = {}\n",
    "for entry in char_xml:\n",
    "    tag = entry.get('tag')\n",
    "    file_name = entry.get('file')\n",
    "    tag_dict = output_object.get(tag, [])\n",
    "    tag_dict.append(file_name)\n",
    "    output_object[tag] = tag_dict\n",
    "\n",
    "with open(os.path.join(data_path, 'char.json'), 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(output_object, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a new json file that contains the label information and the location of the corresponding images associated with those labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': (10, 'char/18/1721.jpg'),\n",
      " '\"': (1, 'char/18/1746.jpg'),\n",
      " '&': (7, 'char/20/1920.jpg'),\n",
      " \"'\": (7, 'char/16/1596.jpg'),\n",
      " '(': (7, 'char/18/1742.jpg'),\n",
      " ')': (7, 'char/18/1747.jpg'),\n",
      " '-': (7, 'char/3/294.jpg'),\n",
      " '.': (17, 'char/9/850.jpg'),\n",
      " '0': (26, 'char/1/36.jpg'),\n",
      " '1': (28, 'char/4/349.jpg'),\n",
      " '2': (35, 'char/1/34.jpg'),\n",
      " '3': (15, 'char/1/26.jpg'),\n",
      " '4': (20, 'char/4/338.jpg'),\n",
      " '5': (15, 'char/1/35.jpg'),\n",
      " '6': (5, 'char/1/27.jpg'),\n",
      " '7': (7, 'char/2/127.jpg'),\n",
      " '8': (14, 'char/1/28.jpg'),\n",
      " '9': (6, 'char/1/29.jpg'),\n",
      " ':': (2, 'char/36/3590.jpg'),\n",
      " '?': (1, 'char/30/2909.jpg'),\n",
      " 'A': (221, 'char/1/57.jpg'),\n",
      " 'B': (52, 'char/1/86.jpg'),\n",
      " 'C': (146, 'char/1/66.jpg'),\n",
      " 'D': (108, 'char/2/124.jpg'),\n",
      " 'E': (326, 'char/1/53.jpg'),\n",
      " 'F': (59, 'char/1/100.jpg'),\n",
      " 'G': (76, 'char/1/51.jpg'),\n",
      " 'H': (81, 'char/2/132.jpg'),\n",
      " 'I': (183, 'char/1/74.jpg'),\n",
      " 'J': (15, 'char/3/261.jpg'),\n",
      " 'K': (28, 'char/1/55.jpg'),\n",
      " 'L': (164, 'char/1/78.jpg'),\n",
      " 'M': (80, 'char/1/64.jpg'),\n",
      " 'N': (168, 'char/1/44.jpg'),\n",
      " 'O': (206, 'char/1/61.jpg'),\n",
      " 'P': (88, 'char/1/90.jpg'),\n",
      " 'Q': (1, 'char/42/4107.jpg'),\n",
      " 'R': (205, 'char/1/52.jpg'),\n",
      " 'S': (246, 'char/1/58.jpg'),\n",
      " 'T': (201, 'char/1/59.jpg'),\n",
      " 'U': (66, 'char/1/85.jpg'),\n",
      " 'V': (28, 'char/2/105.jpg'),\n",
      " 'W': (40, 'char/1/73.jpg'),\n",
      " 'X': (16, 'char/9/859.jpg'),\n",
      " 'Y': (45, 'char/1/65.jpg'),\n",
      " 'Z': (4, 'char/5/471.jpg'),\n",
      " 'a': (240, 'char/1/5.jpg'),\n",
      " 'b': (40, 'char/1/22.jpg'),\n",
      " 'c': (103, 'char/1/31.jpg'),\n",
      " 'd': (101, 'char/1/6.jpg'),\n",
      " 'e': (390, 'char/1/2.jpg'),\n",
      " 'f': (57, 'char/1/4.jpg'),\n",
      " 'g': (65, 'char/2/176.jpg'),\n",
      " 'h': (90, 'char/1/7.jpg'),\n",
      " 'i': (249, 'char/1/10.jpg'),\n",
      " 'j': (7, 'char/5/427.jpg'),\n",
      " 'k': (27, 'char/4/317.jpg'),\n",
      " 'l': (137, 'char/1/3.jpg'),\n",
      " 'm': (95, 'char/1/30.jpg'),\n",
      " 'n': (257, 'char/1/38.jpg'),\n",
      " 'o': (276, 'char/1/37.jpg'),\n",
      " 'p': (58, 'char/2/199.jpg'),\n",
      " 'q': (2, 'char/21/2080.jpg'),\n",
      " 'r': (224, 'char/1/16.jpg'),\n",
      " 's': (200, 'char/1/1.jpg'),\n",
      " 't': (235, 'char/1/46.jpg'),\n",
      " 'u': (90, 'char/3/207.jpg'),\n",
      " 'v': (34, 'char/1/11.jpg'),\n",
      " 'w': (44, 'char/1/47.jpg'),\n",
      " 'x': (21, 'char/12/1137.jpg'),\n",
      " 'y': (47, 'char/2/170.jpg'),\n",
      " '£': (1, 'char/35/3430.jpg'),\n",
      " 'É': (2, 'char/52/5135.jpg'),\n",
      " 'Ñ': (2, 'char/52/5121.jpg'),\n",
      " 'é': (1, 'char/36/3501.jpg')}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "data_path = '../raw_data'\n",
    "\n",
    "with open(os.path.join(data_path, 'char.json'), 'r', encoding='utf-8') as f:\n",
    "    catalog = json.load(f)\n",
    "\n",
    "# Lets see what the data looks like in the catalog. \n",
    "pprint({k: (len(v), v[0]) for k, v in catalog.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have our data to work over, we need to understand how we can extract the pixel information from the jpg images (which are using a compressed format).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ../raw_data/char/1/57.jpg\n",
      "Single Pixel: (189, 182, 164)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0x104220DA0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = '../raw_data'\n",
    "\n",
    "image_to_load = catalog['A'][0]\n",
    "print('Loading:', os.path.join(data_dir, image_to_load))\n",
    "\n",
    "image_data = Image.open(os.path.join(data_dir, image_to_load))\n",
    "print('Single Pixel:', image_data.getdata()[0])\n",
    "image_data.resize((100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the representation of the pixel is currently in RGB form... for our system we want to treat each pixel as a single numeric value, so lets convert the image representation to black and white to see what the differences are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Pixel: 182\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100 at 0x104220978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_white_image = image_data.convert(mode='L')\n",
    "print('Single Pixel:', black_white_image.getdata()[0])\n",
    "black_white_image.resize((100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now we have the image with the pixel representation and it is limited to a single numeric value.  This means that we can create a reader that goes through each image... it we quickly look at each file we should be able to verify the sizes that are found..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2983\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "data_dir = '../raw_data'\n",
    "\n",
    "all_images = Counter([Image.open(os.path.join(data_dir, img)).size \n",
    "                for l in catalog.values()\n",
    "                for img in l])\n",
    "\n",
    "pprint(len(all_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that is something that we need to work on... looks like there are a lot of images of different sizes... for our system we want all images to fit into our 28x28 model so we can do a resize as well as a color correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({((28, 28), 784): 6185})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "data_dir = '../raw_data'\n",
    "\n",
    "formatted_images = [(l, Image.open(os.path.join(data_dir, img)).convert(mode='L').resize((28, 28)))\n",
    "                      for l, images in catalog.items()\n",
    "                      for img in images]\n",
    "\n",
    "Counter([(f.size, len(f.getdata())) for _, f in formatted_images])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we have a clean common dataset to work with... now we haven't really done anything in the way of real feature engineering and we won't until we have a model to run against it... so with that in mind, lets see what happens when we use a simple sklearn model on our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4948 1237\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.shuffle(formatted_images)\n",
    "\n",
    "train_size = int(len(formatted_images) * 0.8)\n",
    "train_data = formatted_images[:train_size]\n",
    "validate_data = formatted_images[train_size:]\n",
    "print(len(train_data), len(validate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "y = [l.isalpha() for l, _ in train_data]\n",
    "X = [list(d.getdata()) for _, d in train_data]\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9586497890295359"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X = [list(d.getdata()) for _, d in validate_data]\n",
    "y_true = [l.isalpha() for l, _ in validate_data]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, a simple binary classifier to determine if the image was a character or not seems to have a reasonable f1 score... So now lets try a one hot encoding of the labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [l for l, _ in train_data]\n",
    "X = [list(d.getdata()) for _, d in train_data]\n",
    "\n",
    "multi_model = LogisticRegression()\n",
    "\n",
    "multi_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07518189167340339"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = [list(d.getdata()) for _, d in validate_data]\n",
    "y_true = [l for l, _ in validate_data]\n",
    "\n",
    "y_pred = multi_model.predict(X)\n",
    "\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while the binary classifier to determine if it is an alpha or not... our accuracy score for exact character types was very poor.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
